# Q1 关联规则中的支持度、置信度和提升度代表的什么，如何计算?
---
## A1:
### 支持度Support:
    - 是个百分比，指的是某个商品组合出现的次数与总次数之间的百分比。支持度越高，代表这个组合出现的频率越大。
    - 支持度(A) = 商品A出现的订单数 / 总订单数

### 置信度Confidence:
    - 是个条件概念，表示在先决条件X发生的情况下，由关联规则”X→Y“推出Y的概率。即在含有X的项集中，含有Y的可能性；如：在购买了商品A的订单中，也含有商品B的可能性：
    - 商品(A->B)的置信度 = 在购买了A的订单中也存在商品B的订单数 / 购买了商品A的订单总数

### 提升度Lift：
    - 商品A的出现，对商品B的出现概率提升的程度：
    - 提升度(A->B) = 置信度(A->B) / 支持度(B)
    - 提升度的三种可能：
        1. 提升度(A->B) > 1：B单独出现的支持度，不如AB在一起时的置信度大，所以说明AB在一起，A的出现对商品B的出现概率有提升，可以放一起；
        2. 提升度(A->B) = 1：B单独出现的支持度和AB在一起时候的置信度相等，说明A的出现对B的出现概率没有影响i，无所谓是否放一起；
        3. 提升度(A->B) < 1：B单独出现的支持度大于AB一起时候的置信度，说明A的出现会使B的出现概率降低，不能放一起。
---
# Q2:关联规则与协同过滤的区别?
## A2:
协同过滤 (Collaborative filtering)依赖用户偏好信息，偏好又称为用户评分（rating）；关联规则分析 (Association Rules，又称 Basket Analysis) 用于从大量数据中挖掘出有价值的数据项之间的相关关系。
### 二者的区别如下：
    1. 关联规则是基于整体事务transaction，而协同过滤是关注用户个性化偏好（评分);
    2. 关联规则的商品组合使用的是购物篮分析，也就是Apriori算法，而协同过滤计算的是相似度;
    3. 关联规则没有利用“用户偏好”，而是基于购物订单进行的频繁项集挖掘;
    4. 关联规则与协同过滤的策略思路是完全不同的类型;
        - 当需求是推荐的基础是且只是当前一次（最近一次）的购买或者点击时，关联规则更适用；
        - 当需求是基于用户历史的行为进行分析，建立一定时间内的偏好排序，在这段时期内持续地按照这个排序来进行推荐，协同过滤更适用。
---
# Q3:为什么我们需要多种推荐算法?（关联规则与协同过滤）
## A3:
- 一般地，关联规则被划分为动态推荐，而协同过滤则更多地被视为静态推荐。    

- 所谓动态推荐，就是推荐的基础是且只是当前一次（最近一次）的购买或者点击。譬如用户在网站上看了一个啤酒，系统就找到与这个啤酒相关的关联规则，然后根据这个规则向用户进行推荐。而静态推荐则是在对用户进行了一定分析的基础上，建立了这个用户在一定时期内的偏好排序，然后在这段时期内持续地按照这个排序来进行推荐。由此可见，关联规则与协同过滤的策略思路是完全不同的类型。

- 两种推荐算法的思考维度不同，适用的场景也不同，有了多种推荐算法，就可以满足更多场景下的需求。很多时候，我们需要把多种推荐方法的结果综合起来做一个混合的推荐。

# Q4:关联规则中的最小支持度、最小置信度该如何确定?
## A4:
- 最小支持度，最小置信度是实验出来的，是超参数。

- 不同的数据最小支持度、最小置信度不一样，最好的方式不断测试出来。
- 最小支持度的经验参考值是0.01~0.5；假如找Top20，可以从高到低输出前20个项集的支持度作为参考。一般数据量越小，最小支持度阈值设置应该越大，否则可能导致所有项集都是频繁项集；而数据量大时，最小支持度阈值设置应该越小，否则可能会无结果。最小支持度与项出现的次数有关，所以我尝试过 sr.value_counts()或one_hot_df.sum(axis=0) 的方法统计并排序，查看他们的频数以作为最小支持度的参考。
- 最小置信度：可能是0.5到1之间的数;先设较小的数，以便得到较多的关联规则；然后再增大到合适大小。
- 提升度：表示使用关联规则可以提升的倍数，是置信度与期望置信度的比值，提升度至少要大于1.
- 对于最小提升度，我没有从DataFrame或者Series的方法去快速拿到参考值，我的理解是，假如我们的目的是想找到是否有提升，那首次运行可以设稍微低于1的值，看看关联规则有多少，因为直接最小提升度设为1的时候，万一运行没结果，就不知道是程序的问题，还是所有频繁项集的提升度都小于1。 

# Q5:都有哪些常见的回归分析方法，评价指标是什么?
## A5:
### 常见回归分析方法：
1. 根据涉及的变量的多少，分为一元线性回归`y=kx+b`和多元线性回归`y=β₁*  x₁+ β₂* x₂+... + b`；
2. 根据自变量的多少，分为简单回归分析`y=kx+b`和多重回归分析`y=β₁*  x₁+ β₂* x₂+... + b`；
3. 按照自变量和因变量之间的关系类型，分为线性回归分析和非线性回归分析（如：多项式回归分析）；

### 实现上述回归分析方法的常见回归模型有：
1. 可以通过LinearRegression() 普通最小二乘法回归模型实现；
2. 使用L2正则化的最小二乘回归模型：岭回归Ridge()
3. 使用L1正则化的回归模型：Lasso回归Lasso()
4. ElasticNet回归
5. 逐步回归
6. 另外，还有一种特殊的回归：逻辑回归，虽然也叫回归，但实际它更适合处理分类问题。

### 评价指标：
1. 损失函数衡量模型好坏：
    - 均方误差MSE(mean-squared_error)
    - 平均绝对误差MAE(mean_absolute_error)
2. 确定系数R方值( r2_score) 表示模型对显示数据拟合的程度作评价。R方值不可导。

